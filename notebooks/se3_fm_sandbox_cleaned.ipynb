{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75dd6906",
   "metadata": {},
   "source": [
    "Notebook for prototyping $\\mathrm{SE}(3)^N$ flow matching, also called frame matching.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d78069dd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f991351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dataclasses\n",
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "import copy\n",
    "import tree\n",
    "from omegaconf import OmegaConf\n",
    "from Bio import PDB\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.spatial.transform import Rotation \n",
    "import random\n",
    "import pickle\n",
    "from Bio import PDB\n",
    "\n",
    "# Feynman imports\n",
    "from diffusion.corruption import so3_utils\n",
    "\n",
    "# FrameDiff imports\n",
    "from data import utils as du\n",
    "from data import parsers\n",
    "from analysis import plotting\n",
    "from model import ipa_pytorch\n",
    "from openfold.utils.rigid_utils import Rigid\n",
    "from data import all_atom\n",
    "from openfold.data import data_transforms\n",
    "from openfold.utils import rigid_utils\n",
    "import analysis.utils as au\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "761158d9",
   "metadata": {},
   "source": [
    "# Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e73512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO(3) helper methods\n",
    "def rotmat_to_skew_matrix(mat):\n",
    "    vec = so3_utils.rotmat_to_rotvec(mat)\n",
    "    return so3_utils.vector_to_skew_matrix(vec)\n",
    "\n",
    "def skew_matrix_to_rotmat(skew):\n",
    "    vec = so3_utils.skew_matrix_to_vector(skew)\n",
    "    return so3_utils.rotvec_to_rotmat(vec)\n",
    "\n",
    "def local_log(point, base_point):\n",
    "    return rotmat_to_skew_matrix(\n",
    "        torch.einsum(\n",
    "            '...ij,...jk->...ik',\n",
    "            rot_transpose(base_point), point\n",
    "        )\n",
    "    )\n",
    "    \n",
    "def multidim_trace(x):\n",
    "    trace_mask = torch.zeros_like(x)\n",
    "    trace_mask[..., torch.arange(3), torch.arange(3)] = 1.0\n",
    "    return torch.sum(trace_mask * x, dim=(-1, -2))\n",
    "    \n",
    "def geodesic_dist(x, y):\n",
    "    A = rotmat_to_skew_matrix(\n",
    "        rot_mult(rot_transpose(x), y)\n",
    "    )\n",
    "    return torch.sqrt(\n",
    "        multidim_trace(\n",
    "            rot_mult(A, rot_transpose(A))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "def rot_transpose(x):\n",
    "    return torch.transpose(x, -1, -2)\n",
    "\n",
    "def rot_mult(x, y):\n",
    "    return torch.einsum('...ij,...jk->...ik', x, y)\n",
    "\n",
    "def rot_vf(rot_t, rot_1):\n",
    "    return so3_utils.rotmat_to_rotvec(\n",
    "        torch.einsum(\n",
    "            '...ij,...jk->...ik', rot_transpose(rot_t), rot_1)\n",
    "    )\n",
    "\n",
    "def geodesic_t(t, mat, base_mat):\n",
    "    vec_vf = rot_vf(base_mat, mat)\n",
    "    mat_t = so3_utils.rotvec_to_rotmat(t*vec_vf)\n",
    "    return torch.einsum('...ij,...jk->...ik', base_mat, mat_t)\n",
    "\n",
    "to_numpy = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "ts = np.linspace(1e-3, 1.0, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e268a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for processing and parsing features from PDB files.\n",
    "parser = PDB.PDBParser(QUIET=True)\n",
    "def parse_pdb_file(pdb_path):\n",
    "    structure = parser.get_structure('test', pdb_path)\n",
    "\n",
    "    # Take out chain\n",
    "    all_struct_chains = {\n",
    "        chain.id.upper(): chain\n",
    "        for chain in structure.get_chains()\n",
    "    }\n",
    "    struct_chain = all_struct_chains['A']\n",
    "\n",
    "    # Get features\n",
    "    chain_prot = parsers.process_chain(struct_chain, 'A')\n",
    "    chain_dict = dataclasses.asdict(chain_prot)\n",
    "    chain_dict = du.parse_chain_feats(chain_dict)\n",
    "\n",
    "    # Extract frames\n",
    "    chain_feats = {\n",
    "        'aatype': torch.tensor(chain_dict['aatype']).long(),\n",
    "        'all_atom_positions': torch.tensor(chain_dict['atom_positions']).double(),\n",
    "        'all_atom_mask': torch.tensor(chain_dict['atom_mask']).double()\n",
    "    }\n",
    "    chain_feats = data_transforms.atom37_to_frames(chain_feats)\n",
    "    chain_feats = data_transforms.make_atom14_masks(chain_feats)\n",
    "    chain_feats = data_transforms.make_atom14_positions(chain_feats)\n",
    "    chain_feats = data_transforms.atom37_to_torsion_angles()(chain_feats)\n",
    "\n",
    "    # Feature processing\n",
    "    final_feats = {\n",
    "        'rigids_0': chain_feats['rigidgroups_gt_frames'][:, 0],\n",
    "        'res_mask': chain_dict['bb_mask']\n",
    "    }\n",
    "    pad_mask = final_feats['res_mask'] > 0\n",
    "    final_feats = tree.map_structure(lambda x: x[pad_mask], final_feats)\n",
    "    return final_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2b3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "979f9480",
   "metadata": {},
   "source": [
    "# SE(3) Neural ODE on a protein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20fa6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feats = parse_pdb_file('1qys.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ed588",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_numpy = lambda x: x.cpu().numpy()\n",
    "\n",
    "rigids_1 = rigid_utils.Rigid.from_tensor_4x4(final_feats['rigids_0'])\n",
    "trans_1 = rigids_1.get_trans().float() / 10.0\n",
    "mats_1 = rigids_1.get_rots().get_rot_mats().float()\n",
    "\n",
    "num_res = trans_1.shape[0]\n",
    "\n",
    "mats_0 = Rotation.random(num_res)\n",
    "mats_0 = mats_0.as_matrix()\n",
    "mats_0 = torch.tensor(mats_0).float()\n",
    "trans_0 = torch.randn(num_res, 3).float()\n",
    "\n",
    "np_trans_1 = to_numpy(trans_1)\n",
    "np_mats_1 = to_numpy(mats_1)\n",
    "\n",
    "r3_vf_t = lambda t, trans, trans_t: (trans - trans_t) / (1 - t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f67fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ODE\n",
    "mats_1 = mats_1.float()\n",
    "t_1 = ts[0]\n",
    "manual_traj = [(mats_0.float(), trans_0)]\n",
    "for t_2 in ts[1:]:\n",
    "    d_t = t_2 - t_1\n",
    "    mats_t, trans_t = manual_traj[-1]\n",
    "    mats_t_1 = geodesic_t(d_t / (1 - t_1), mats_1, mats_t)\n",
    "    trans_t_1 = trans_t + r3_vf_t(t_1, trans_1, trans_t) * d_t\n",
    "    t_1 = t_2\n",
    "    manual_traj.append((mats_t_1, trans_t_1))\n",
    "trans_traj = [x[1] for x in manual_traj]\n",
    "mats_traj = [x[0] for x in manual_traj]\n",
    "trans_traj = torch.stack(trans_traj, dim=0).detach().numpy()\n",
    "mats_traj = torch.stack(mats_traj, dim=0).detach().numpy()\n",
    "vec_traj = so3_utils.rotmat_to_rotvec(torch.tensor(mats_traj)).numpy()\n",
    "\n",
    "np.testing.assert_allclose(mats_traj[-1], mats_1, rtol=1e-2)\n",
    "np.testing.assert_allclose(trans_traj[-1], trans_1, rtol=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895880fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rots_t1_dist_traj = np.mean(to_numpy(geodesic_dist(\n",
    "    torch.tensor(mats_traj),\n",
    "    torch.tensor(mats_1[None])\n",
    ")), axis=-1)\n",
    "\n",
    "rots_t0_dist_traj = np.mean(to_numpy(geodesic_dist(\n",
    "    torch.tensor(mats_traj),\n",
    "    torch.tensor(mats_0[None])\n",
    ")), axis=-1)\n",
    "\n",
    "trans_t1_dist_traj = np.mean(np.linalg.norm(trans_traj - to_numpy(trans_1)[None], axis=-1), axis=-1)\n",
    "\n",
    "trans_t0_dist_traj = np.mean(np.linalg.norm(trans_traj - to_numpy(trans_0)[None], axis=-1), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts, trans_t0_dist_traj, label=r'Translations: $||x_t-x_0||_2^2$')\n",
    "plt.plot(ts, trans_t1_dist_traj, label=r'Translations: $||x_t-x_1||_2^2$')  \n",
    "\n",
    "plt.plot(ts, rots_t0_dist_traj, label=r'Rotations: $||r_t-r_0||_g^2$')\n",
    "plt.plot(ts, rots_t1_dist_traj, label=r'Rotations: $||r_t-r_1||_g^2$')    \n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Distance')\n",
    "plt.legend()\n",
    "plt.title('Protein SE(3) flow trajectories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb220d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "t_indices = [int(x) for x in np.linspace(0, 100-1, 9)]\n",
    "for i,t_idx in enumerate(t_indices):\n",
    "    t = ts[t_idx]\n",
    "    ax = fig.add_subplot(3, 3, i+1, projection='3d')\n",
    "    plotting.plt_3d(trans_traj[t_idx], ax, c=np.linspace(0, 1, num_res), mode='scatter', s=20)\n",
    "    plotting.plt_3d(trans_traj[t_idx], ax, mode='line', s=30)\n",
    "    ax.set_title(f't={t:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04797d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rots = rigid_utils.Rotation(rot_mats = torch.tensor(mats_traj))\n",
    "rigids = rigid_utils.Rigid(rots=rots, trans=torch.tensor(trans_traj)*10.0)\n",
    "\n",
    "atom37_0 = all_atom.compute_backbone(\n",
    "    rigids,\n",
    "    torch.zeros(trans_traj.shape[0], trans_traj.shape[1], 2)\n",
    ")[0]\n",
    "\n",
    "traj = to_numpy(atom37_0) \n",
    "\n",
    "# Save flow to PDB\n",
    "saved_path = au.write_prot_to_pdb(\n",
    "    traj,\n",
    "    './ode_traj.pdb',\n",
    "    no_indexing=True,\n",
    ")\n",
    "\n",
    "# Save flow to PDB\n",
    "saved_path = au.write_prot_to_pdb(\n",
    "    traj[-1],\n",
    "    './ode_final.pdb',\n",
    "    no_indexing=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd58209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55a0a9c2",
   "metadata": {},
   "source": [
    "# Learn SE(3) flow matching"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d96e17e",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0381292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, prot_feats, steps, scale_factor,\n",
    "            crop=100, noise_trans=True, noise_rots=True\n",
    "        ):\n",
    "        self.prot_feats = prot_feats\n",
    "        self.steps = steps\n",
    "        self.scale_factor = scale_factor\n",
    "        self.crop = crop\n",
    "        self.noise_trans = noise_trans\n",
    "        self.noise_rots = noise_rots\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps   \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        t = random.random()\n",
    "        prot_feats = self.prot_feats[i % len(self.prot_feats)]\n",
    "        num_res = prot_feats['res_mask'].shape[0]\n",
    "        gt_bb_rigid = rigid_utils.Rigid.from_tensor_4x4(\n",
    "            prot_feats['rigids_0'])\n",
    "        \n",
    "        final_feats = copy.deepcopy(prot_feats)\n",
    "        \n",
    "        # Scaled translations\n",
    "        # Scale down to nm\n",
    "        final_feats['trans_1'] = gt_bb_rigid.get_trans() * self.scale_factor\n",
    "        final_feats['trans_0'] = torch.randn(num_res, 3)\n",
    "        if self.noise_trans:\n",
    "            final_feats['trans_t'] = (1 - t) * final_feats['trans_0'] + t * final_feats['trans_1']\n",
    "        else:\n",
    "            final_feats['trans_t'] = final_feats['trans_1']\n",
    "        final_feats['trans_vf'] = final_feats['trans_1'] - final_feats['trans_t']\n",
    "        \n",
    "        final_feats['rots_1'] = gt_bb_rigid.get_rots().get_rot_mats().float()\n",
    "        final_feats['rots_0'] = torch.tensor(\n",
    "            Rotation.random(num_res).as_matrix()).float()\n",
    "        if self.noise_rots:\n",
    "            final_feats['rots_t'] = geodesic_t(\n",
    "                t, final_feats['rots_1'], final_feats['rots_0'])\n",
    "        else:\n",
    "            final_feats['rots_t'] = final_feats['rots_1']\n",
    "        final_feats['rots_vf'] = rot_vf(\n",
    "            final_feats['rots_t'],\n",
    "            final_feats['rots_1']\n",
    "        )\n",
    "\n",
    "        rots = rigid_utils.Rotation(rot_mats=final_feats['rots_t'])\n",
    "        final_feats['rigids_t'] = rigid_utils.Rigid.to_tensor_4x4(\n",
    "            rigid_utils.Rigid(\n",
    "                rots=rots,\n",
    "                # Scale up to angstroms\n",
    "                trans=final_feats['trans_t'] / self.scale_factor\n",
    "            )\n",
    "        )\n",
    "\n",
    "        def _map(x):\n",
    "            x = torch.tensor(x).type(torch.float32)\n",
    "            if self.crop is not None:\n",
    "                return x[:self.crop]\n",
    "            return x\n",
    "        final_feats = tree.map_structure(_map, final_feats)\n",
    "        final_feats['t'] = torch.tensor(t)[None].type(torch.float32)\n",
    "        return final_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc454f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b29b509b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c920c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_index_embedding(indices, embed_size, max_len=2056):\n",
    "    \"\"\"Creates sine / cosine positional embeddings from a prespecified indices.\n",
    "\n",
    "    Args:\n",
    "        indices: offsets of size [..., N_edges] of type integer\n",
    "        max_len: maximum length.\n",
    "        embed_size: dimension of the embeddings to create\n",
    "\n",
    "    Returns:\n",
    "        positional embedding of shape [N, embed_size]\n",
    "    \"\"\"\n",
    "    K = torch.arange(embed_size//2, device=indices.device)\n",
    "    pos_embedding_sin = torch.sin(\n",
    "        indices[..., None] * math.pi / (max_len**(2*K[None]/embed_size))).to(indices.device)\n",
    "    pos_embedding_cos = torch.cos(\n",
    "        indices[..., None] * math.pi / (max_len**(2*K[None]/embed_size))).to(indices.device)\n",
    "    pos_embedding = torch.cat([\n",
    "        pos_embedding_sin, pos_embedding_cos], axis=-1)\n",
    "    return pos_embedding\n",
    "\n",
    "def get_timestep_embedding(timesteps, embedding_dim, max_positions=1000):\n",
    "    # Code from https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/nn.py\n",
    "    assert len(timesteps.shape) == 1\n",
    "    timesteps = timesteps * max_positions\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(max_positions) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) * -emb)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = F.pad(emb, (0, 1), mode='constant')\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb\n",
    "\n",
    "class VFModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model_conf):\n",
    "        super(VFModel, self).__init__()\n",
    "        self._model_conf = model_conf\n",
    "        self._ipa_conf = model_conf.ipa\n",
    "        self.scale_pos = lambda x: x * ipa_conf.coordinate_scaling\n",
    "        self.scale_rigids = lambda x: x.apply_trans_fn(self.scale_pos)\n",
    "\n",
    "        self.unscale_pos = lambda x: x / ipa_conf.coordinate_scaling\n",
    "        self.unscale_rigids = lambda x: x.apply_trans_fn(self.unscale_pos)\n",
    "        \n",
    "        node_embed_size = self._model_conf.node_embed_size\n",
    "        self.node_embedder = nn.Sequential(\n",
    "            nn.Linear(node_embed_size*2, node_embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(node_embed_size, node_embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(node_embed_size, node_embed_size),\n",
    "            nn.LayerNorm(node_embed_size),\n",
    "        )\n",
    "        \n",
    "        self.trunk = nn.ModuleDict()\n",
    "\n",
    "        for b in range(ipa_conf.num_blocks):\n",
    "            self.trunk[f'ipa_{b}'] = ipa_pytorch.InvariantPointAttention(ipa_conf)\n",
    "            self.trunk[f'ipa_ln_{b}'] = nn.LayerNorm(ipa_conf.c_s)\n",
    "            self.trunk[f'skip_embed_{b}'] = ipa_pytorch.Linear(\n",
    "                self._model_conf.node_embed_size,\n",
    "                self._ipa_conf.c_skip,\n",
    "                init=\"final\"\n",
    "            )\n",
    "            tfmr_in = ipa_conf.c_s + self._ipa_conf.c_skip\n",
    "            tfmr_layer = torch.nn.TransformerEncoderLayer(\n",
    "                d_model=tfmr_in,\n",
    "                nhead=ipa_conf.seq_tfmr_num_heads,\n",
    "                dim_feedforward=tfmr_in,\n",
    "                batch_first=True,\n",
    "                dropout=0.0,\n",
    "                norm_first=False\n",
    "            )\n",
    "            self.trunk[f'seq_tfmr_{b}'] = torch.nn.TransformerEncoder(\n",
    "                tfmr_layer, ipa_conf.seq_tfmr_num_layers)\n",
    "            self.trunk[f'post_tfmr_{b}'] = ipa_pytorch.Linear(\n",
    "                tfmr_in, ipa_conf.c_s, init=\"final\")\n",
    "            self.trunk[f'node_transition_{b}'] = ipa_pytorch.StructureModuleTransition(\n",
    "                c=ipa_conf.c_s)\n",
    "            self.trunk[f'bb_update_{b}'] = ipa_pytorch.BackboneUpdate(ipa_conf.c_s)\n",
    "\n",
    "            if b < ipa_conf.num_blocks-1:\n",
    "                # No edge update on the last block.\n",
    "                edge_in = self._model_conf.edge_embed_size\n",
    "                self.trunk[f'edge_transition_{b}'] = ipa_pytorch.EdgeTransition(\n",
    "                    node_embed_size=ipa_conf.c_s,\n",
    "                    edge_embed_in=edge_in,\n",
    "                    edge_embed_out=self._model_conf.edge_embed_size,\n",
    "                )\n",
    "\n",
    "    def forward(self, input_feats):\n",
    "        # Initial node and edge features\n",
    "        node_mask = input_feats['res_mask'].type(torch.float32)\n",
    "        num_batch = node_mask.shape[0]\n",
    "        num_res = node_mask.shape[1]\n",
    "        node_indices = torch.arange(num_res)\n",
    "        index_embed = get_index_embedding(\n",
    "            node_indices, self._model_conf.node_embed_size\n",
    "        )[None].repeat(num_batch, 1, 1).type(torch.float32).to('cuda')\n",
    "        t_embed = get_timestep_embedding(\n",
    "            input_feats['t'][:, 0],\n",
    "            self._model_conf.node_embed_size\n",
    "        )[:, None, :].repeat(1, num_res, 1).type(torch.float32).to('cuda')\n",
    "        init_node_feats = torch.concat(\n",
    "            [index_embed, t_embed], dim=-1)\n",
    "        init_node_embed = self.node_embedder(\n",
    "            init_node_feats\n",
    "        )\n",
    "        \n",
    "        edge_mask = node_mask[..., None] * node_mask[..., None, :]\n",
    "        edge_embed = init_node_embed[:, :, None, :] + init_node_embed[:, None, :, :]\n",
    "        edge_embed = edge_embed.type(torch.float32)\n",
    "\n",
    "        # Initial rigids\n",
    "        init_frames = input_feats['rigids_t'].type(torch.float32)\n",
    "        rigids_t = Rigid.from_tensor_4x4(torch.clone(init_frames))\n",
    "        curr_rigids = Rigid.from_tensor_4x4(torch.clone(init_frames))\n",
    "\n",
    "        # Main trunk\n",
    "        curr_rigids = self.scale_rigids(curr_rigids)\n",
    "        init_node_embed = init_node_embed * node_mask[..., None]\n",
    "        node_embed = init_node_embed * node_mask[..., None]\n",
    "        for b in range(self._ipa_conf.num_blocks):\n",
    "            ipa_embed = self.trunk[f'ipa_{b}'](\n",
    "                node_embed,\n",
    "                edge_embed,\n",
    "                curr_rigids,\n",
    "                node_mask)\n",
    "            ipa_embed *= node_mask[..., None]\n",
    "            node_embed = self.trunk[f'ipa_ln_{b}'](node_embed + ipa_embed)\n",
    "            seq_tfmr_in = torch.cat([\n",
    "                node_embed, self.trunk[f'skip_embed_{b}'](init_node_embed)\n",
    "            ], dim=-1)\n",
    "            seq_tfmr_out = self.trunk[f'seq_tfmr_{b}'](\n",
    "                seq_tfmr_in, src_key_padding_mask=1 - node_mask)\n",
    "            node_embed = node_embed + self.trunk[f'post_tfmr_{b}'](seq_tfmr_out)\n",
    "            node_embed = self.trunk[f'node_transition_{b}'](node_embed)\n",
    "            node_embed = node_embed * node_mask[..., None]\n",
    "            rigid_update = self.trunk[f'bb_update_{b}'](\n",
    "                node_embed * node_mask[..., None])\n",
    "            curr_rigids = curr_rigids.compose_q_update_vec(\n",
    "                rigid_update, node_mask[..., None])\n",
    "\n",
    "            if b < self._ipa_conf.num_blocks-1:\n",
    "                edge_embed = self.trunk[f'edge_transition_{b}'](\n",
    "                    node_embed, edge_embed)\n",
    "                edge_embed *= edge_mask[..., None]\n",
    "        \n",
    "        pred_trans = curr_rigids.get_trans()\n",
    "        trans_t = rigids_t.get_trans()\n",
    "        trans_vf = pred_trans - trans_t\n",
    "        pred_rots = curr_rigids.get_rots().get_rot_mats()\n",
    "        rots_t = rigids_t.get_rots().get_rot_mats()\n",
    "        rots_vf = rot_vf(rots_t, pred_rots)\n",
    "        return {\n",
    "            'trans_vf': trans_vf,\n",
    "            'rots_vf': rots_vf,\n",
    "            'pred_trans': pred_trans,\n",
    "            'pred_rots': pred_rots\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de8fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15b050ad",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879cffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top7_feats = parse_pdb_file('1qys.pdb')\n",
    "efhand_feats = parse_pdb_file('1b9a.pdb')\n",
    "bet_feats = parse_pdb_file('5o3a.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b22290",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load config\n",
    "base_conf = OmegaConf.load('/home/t-jasonyim/projects/feynman/projects/sampling/experimental/jyim/se3_diffusion/config/base.yaml')\n",
    "model_conf = base_conf.model\n",
    "ipa_conf = model_conf.ipa\n",
    "\n",
    "scale_factor = 0.1\n",
    "\n",
    "# Small model config\n",
    "embed_size = 64\n",
    "model_conf.node_embed_size = embed_size\n",
    "model_conf.edge_embed_size = embed_size\n",
    "ipa_conf.c_hidden = embed_size\n",
    "ipa_conf.c_skip = 32\n",
    "ipa_conf.no_heads = 2\n",
    "ipa_conf.no_qk_points = 8\n",
    "ipa_conf.no_v_points = 8\n",
    "ipa_conf.seq_tfmr_num_heads = 2\n",
    "ipa_conf.seq_tfmr_num_layers = 1\n",
    "ipa_conf.num_blocks = 2\n",
    "ipa_conf.coordinate_scaling = scale_factor\n",
    "\n",
    "# Initialize model\n",
    "model = VFModel(model_conf)\n",
    "model = model.to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Construct dataset\n",
    "noise_trans = True\n",
    "noise_rots = True\n",
    "flow_dataset = FlowDataset(\n",
    "    [top7_feats, efhand_feats],\n",
    "    # [top7_feats, efhand_feats, bet_feats],\n",
    "    1_000_000,\n",
    "    scale_factor,\n",
    "    crop=90,\n",
    "    noise_trans=noise_trans,\n",
    "    noise_rots=noise_rots,\n",
    ")\n",
    "train_dataloader = DataLoader(flow_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "all_ts = []\n",
    "all_rot_losses = []\n",
    "all_trans_losses = []\n",
    "epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train loop\n",
    "start_time = time.time()\n",
    "print_interval = 500\n",
    "for i, feats in enumerate(train_dataloader):\n",
    "    feats = tree.map_structure(lambda x: x.to('cuda'), feats)\n",
    "    gt_trans_vf = feats['trans_vf']\n",
    "    gt_rots_vf = feats['rots_vf']\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    model_out = model(feats)\n",
    "    pred_trans_vf = model_out['trans_vf']\n",
    "    pred_rots_vf = model_out['rots_vf']\n",
    "    if noise_trans:\n",
    "        trans_loss = torch.mean(\n",
    "            (model_out['pred_trans'] - feats['trans_1']) ** 2\n",
    "        )\n",
    "    else:\n",
    "        trans_loss = torch.tensor(0)\n",
    "\n",
    "    if noise_rots:\n",
    "        rots_loss = torch.mean((pred_rots_vf - gt_rots_vf) ** 2)\n",
    "    else:\n",
    "        rots_loss = torch.tensor(0)\n",
    "    vf_loss = trans_loss + rots_loss\n",
    "    vf_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    step_loss = to_numpy(vf_loss)\n",
    "    all_losses.append(step_loss)\n",
    "    all_rot_losses.append(to_numpy(rots_loss))\n",
    "    all_trans_losses.append(to_numpy(trans_loss))\n",
    "    all_ts.append(to_numpy(feats['t']))\n",
    "    epoch_losses.append(step_loss)\n",
    "    if i % print_interval == 0:\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f'On step {i}: loss={np.mean(epoch_losses):.2f}, time={print_interval/epoch_time:.2f}(steps/sec)')\n",
    "        start_time = time.time()\n",
    "        epoch_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_losses, label='SE(3)')\n",
    "plt.plot(all_rot_losses, label='SO(3)')\n",
    "plt.plot(all_trans_losses, label='R^3')\n",
    "plt.legend()\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "pkl_path = 'weights.pth'\n",
    "pkl_dict = {\n",
    "    'model': copy.deepcopy(model.state_dict()),\n",
    "    'conf': model_conf,\n",
    "}\n",
    "torch.save(pkl_dict, pkl_path, pickle_protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4c35c41",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bddf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_weights = torch.load(pkl_path, map_location='cuda')\n",
    "# model = VFModel(loaded_weights['conf'])\n",
    "# model = sample_model.to('cuda')\n",
    "# model.load_state_dict(loaded_weights['model'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo features\n",
    "feats = next(iter(train_dataloader))\n",
    "feats = tree.map_structure(lambda x: x[:1].to('cuda'), feats)\n",
    "num_batch, num_res = feats['res_mask'].shape[:2]\n",
    "\n",
    "trans_0 = torch.randn(num_batch, num_res, 3)\n",
    "\n",
    "if noise_trans:\n",
    "    feats['trans_t'] = copy.deepcopy(trans_0)\n",
    "else:\n",
    "    feats['trans_t'] = feats['trans_1']\n",
    "feats['trans_t'] = feats['trans_t'].to('cuda')\n",
    "rots_0 = torch.tensor(\n",
    "    Rotation.random(num_res).as_matrix()).float()\n",
    "\n",
    "if noise_rots:\n",
    "    feats['rots_t'] = copy.deepcopy(rots_0)[None].repeat(num_batch, 1, 1, 1)\n",
    "else:\n",
    "    feats['rots_t'] = feats['rots_1']\n",
    "feats['rots_t'] = feats['rots_t'].to('cuda')\n",
    "\n",
    "rots = rigid_utils.Rotation(rot_mats=feats['rots_t'])\n",
    "feats['rigids_t'] = rigid_utils.Rigid.to_tensor_4x4(\n",
    "    rigid_utils.Rigid(\n",
    "        rots=rots,\n",
    "        # Scale up to angstroms\n",
    "        trans=feats['trans_t'] / scale_factor\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rigid(rots, trans):\n",
    "    rots = rigid_utils.Rotation(rot_mats=rots)\n",
    "    return rigid_utils.Rigid.to_tensor_4x4(\n",
    "        rigid_utils.Rigid(\n",
    "            rots=rots, trans=trans\n",
    "        )\n",
    "    )\n",
    "r3_vf_t = lambda t, trans, trans_t: (trans - trans_t) / (1 - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rigids_traj = [copy.deepcopy(feats['rigids_t']).to('cuda')]\n",
    "ts = np.linspace(1e-3, 1.0, 100)\n",
    "t_1 = ts[0]\n",
    "for t_2 in ts[1:]:\n",
    "    d_t = t_2 - t_1\n",
    "    rigids_t_1 = rigids_traj[-1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats['rigids_t'] = rigids_t_1\n",
    "        feats['t'] = torch.ones_like(feats['t']) * t_1\n",
    "        model_out = model(feats)\n",
    "    rigids_t_1 = Rigid.from_tensor_4x4(rigids_t_1)\n",
    "    \n",
    "    # pred_trans_1 = feats['trans_1']\n",
    "    # pred_rots_1 = feats['rots_1']\n",
    "    pred_trans_1 = model_out['pred_trans']\n",
    "    pred_rots_1 = model_out['pred_rots']\n",
    "\n",
    "    # Perform translation updates in scaled coordinates (nm)\n",
    "    trans_t_1 = rigids_t_1.get_trans() * scale_factor\n",
    "    if noise_trans:\n",
    "        trans_t_2 = trans_t_1 + r3_vf_t(t_1, pred_trans_1, trans_t_1) * d_t\n",
    "    else:\n",
    "        trans_t_2 = trans_t_1\n",
    "    # Scale back up since IPA expects angstroms.\n",
    "    trans_t_2 /= scale_factor\n",
    "    \n",
    "    rots_t_1 = rigids_t_1.get_rots().get_rot_mats()\n",
    "    if noise_rots:\n",
    "        rots_t_2 = geodesic_t(d_t / (1 - t_1), pred_rots_1, rots_t_1)\n",
    "    else:\n",
    "        rots_t_2 = rots_t_1\n",
    "    t_1 = t_2\n",
    "    rigids_traj.append(\n",
    "        copy.deepcopy(\n",
    "            create_rigid(\n",
    "                rots_t_2, trans_t_2\n",
    "            )\n",
    "        ).to('cuda')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68557159",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans = []\n",
    "all_rots = []\n",
    "for rigid in rigids_traj:\n",
    "    rigid = Rigid.from_tensor_4x4(rigid)\n",
    "    trans = rigid.get_trans()\n",
    "    rots = rigid.get_rots().get_rot_mats()\n",
    "    all_trans.append(trans)\n",
    "    all_rots.append(rots)\n",
    "trans_traj = torch.concatenate(all_trans)\n",
    "rots_traj = torch.concatenate(all_rots)\n",
    "rots = rigid_utils.Rotation(rot_mats = rots_traj)\n",
    "rigids = rigid_utils.Rigid(rots=rots, trans=trans_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom37_0 = all_atom.compute_backbone(\n",
    "    rigids,\n",
    "    torch.zeros(trans_traj.shape[0], trans_traj.shape[1], 2)\n",
    ")[0]\n",
    "\n",
    "traj = to_numpy(atom37_0) \n",
    "\n",
    "# Save flow to PDB\n",
    "saved_path = au.write_prot_to_pdb(\n",
    "    traj,\n",
    "    './sample_traj_2.pdb',\n",
    "    no_indexing=True,\n",
    ")\n",
    "\n",
    "# Save flow to PDB\n",
    "saved_path = au.write_prot_to_pdb(\n",
    "    traj[-1],\n",
    "    './sample_2.pdb',\n",
    "    no_indexing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np_trans_traj = to_numpy(trans_traj)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "t_indices = [int(x) for x in np.linspace(0, len(ts)-1, 9)]\n",
    "for i,t_idx in enumerate(t_indices):\n",
    "    t = ts[t_idx]\n",
    "    ax = fig.add_subplot(3, 3, i+1, projection='3d')\n",
    "    plotting.plt_3d(np_trans_traj[t_idx], ax, c=np.linspace(0, 1, num_res), mode='scatter', s=20)\n",
    "    plotting.plt_3d(np_trans_traj[t_idx], ax, mode='line', s=30)\n",
    "    ax.set_title(f't={t:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dae953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
