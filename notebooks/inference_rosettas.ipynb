{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from models.flow_module import FlowModule\n",
    "import torch\n",
    "from data.pdb_dataloader import PdbDataModule\n",
    "import glob\n",
    "import GPUtil\n",
    "from data import utils as du\n",
    "import numpy as np\n",
    "import tree\n",
    "from data import so3_utils\n",
    "from data import all_atom\n",
    "from analysis import utils as au\n",
    "from openfold.utils.superimposition import superimpose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def atom37_from_trans_rot(trans, rots, res_mask):\n",
    "        rigids = du.create_rigid(rots, trans)\n",
    "        atom37 = all_atom.compute_backbone(\n",
    "            rigids,\n",
    "            torch.zeros(\n",
    "                trans.shape[0],\n",
    "                trans.shape[1],\n",
    "                2,\n",
    "                device=trans.device\n",
    "            )\n",
    "        )[0]\n",
    "        atom37 = atom37.detach().cpu()\n",
    "        batch_atom37 = []\n",
    "        num_batch = res_mask.shape[0]\n",
    "        for i in range(num_batch):\n",
    "            batch_atom37.append(\n",
    "                du.adjust_oxygen_pos(atom37[i], res_mask[i])\n",
    "            )\n",
    "        return torch.stack(batch_atom37)\n",
    "\n",
    "def process_trans_rot_traj(trans_traj, rots_traj, res_mask):\n",
    "    res_mask = res_mask.detach().cpu()\n",
    "    atom37_traj = [\n",
    "         atom37_from_trans_rot(trans, rots, res_mask)\n",
    "         for trans, rots in zip(trans_traj, rots_traj) \n",
    "    ]\n",
    "    atom37_traj = torch.stack(atom37_traj).swapaxes(0, 1)\n",
    "    return atom37_traj\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'notebook_samples/'\n",
    "num_timesteps = 100\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup lightning module\n",
    "\n",
    "# ckpt_dir = '../ckpt/se3-fm/se3_vf_loss_normal_schedule/2023-09-18_14-12-09'\n",
    "# ckpt_dir = '../ckpt/se3-fm/se3_vf_loss_trans_scale/2023-09-18_22-15-09'\n",
    "# ckpt_dir = '../ckpt/se3-fm/se3_vf_loss/2023-09-18_14-17-30'\n",
    "# ckpt_dir = '../ckpt/se3-fm/se3_vf_loss_normal_schedule/2023-09-18_14-12-09'\n",
    "# ckpt_dir = 'ckpt/se3-fm/se3_vf_loss/2023-09-18_11-22-19'\n",
    "# ckpt_dir = '../ckpt/se3-fm/baseline/2023-09-17_21-30-00'\n",
    "# ckpt_dir = '../ckpt/se3-fm/baseline_fixed/2023-09-13_08-12-53'\n",
    "# ckpt_dir = 'ckpt/se3-fm/warm_start_dist_loss/2023-09-15_00-51-09'\n",
    "# ckpt_path = sorted(glob.glob(os.path.join(ckpt_dir, '*.ckpt')))[-1]\n",
    "\n",
    "\n",
    "# ckpt_dir = '../ckpt/se3-fm/se3_vf_loss_trans_scale/2023-09-18_22-15-09'\n",
    "ckpt_dir = '../ckpt/se3-fm/se3_vf_loss_normal_schedule/2023-09-18_14-12-09'\n",
    "# ckpt_path = '../ckpt/se3-fm/se3_vf_loss_trans_scale/2023-09-18_22-15-09/epoch=49-step=127985.ckpt'\n",
    "# ckpt_path = os.path.join(ckpt_dir, 'epoch=24-step=78760.ckpt')\n",
    "# ckpt_path = os.path.join(ckpt_dir, 'epoch=49-step=127985.ckpt')\n",
    "\n",
    "# ckpt_path = os.path.join(ckpt_dir, 'epoch=9-step=39380.ckpt')\n",
    "# ckpt_path = os.path.join(ckpt_dir, 'epoch=31-step=126016.ckpt')\n",
    "ckpt_path = os.path.join(ckpt_dir, 'last.ckpt')\n",
    "\n",
    "print(ckpt_path)\n",
    "base_path = '../configs/base.yaml'\n",
    "base_cfg = OmegaConf.load(base_path)\n",
    "\n",
    "cfg_path = os.path.join(ckpt_dir, 'config.yaml')\n",
    "ckpt_cfg = OmegaConf.load(cfg_path)\n",
    "\n",
    "OmegaConf.set_struct(base_cfg, False)\n",
    "OmegaConf.set_struct(ckpt_cfg, False)\n",
    "cfg = OmegaConf.merge(base_cfg, ckpt_cfg)\n",
    "cfg.experiment.checkpointer.dirpath = './'\n",
    "cfg.experiment.rescale_time = False\n",
    "cfg.data.dataset.csv_path = '../preprocessed/metadata.csv'\n",
    "\n",
    "flow = FlowModule.load_from_checkpoint(\n",
    "    checkpoint_path=ckpt_path,\n",
    "    model_cfg=cfg.model,\n",
    "    experiment_cfg=cfg.experiment\n",
    ")\n",
    "_ = flow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data module\n",
    "data_module = PdbDataModule(cfg.data)\n",
    "data_module.setup('fit')\n",
    "train_dataloader = data_module.train_dataloader(\n",
    "    num_replicas=1,\n",
    "    rank=1\n",
    ")\n",
    "data_iter = iter(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a reasonable batch\n",
    "stop_search = False\n",
    "while not stop_search: \n",
    "    batch = next(data_iter)\n",
    "    num_batch, num_res, _ = batch['trans_1'].shape\n",
    "    if num_res < 80:\n",
    "        stop_search = True\n",
    "\n",
    "print(f'Found batch with {num_res} residues, {num_batch} batch size')\n",
    "\n",
    "# Set up device and cuda\n",
    "num_batch, num_res, _ = batch['trans_1'].shape\n",
    "cuda_id = GPUtil.getAvailable(order='memory', limit = 8)[0]\n",
    "device = f'cuda:{cuda_id}'\n",
    "# device = 'cpu'\n",
    "print(f'Using device {device}')\n",
    "flow.model = flow.model.to(device)\n",
    "batch = tree.map_structure(lambda x: x.to(device), batch)\n",
    "num_batch = batch['res_mask'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction at different timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ca_pos = batch['trans_1']\n",
    "device = gt_ca_pos.device\n",
    "num_batch = gt_ca_pos.shape[0]\n",
    "ts = np.linspace(1e-3, 1.0, num_timesteps)\n",
    "all_pred_ca = []\n",
    "all_pred_transrot = []\n",
    "all_pred_rots_vf = []\n",
    "all_gt_atom37 = []\n",
    "all_gt_rots_vf = []\n",
    "\n",
    "for i,t in enumerate(ts):\n",
    "    if i % 100 == 0:\n",
    "        print(f'On t={t:.2f}')\n",
    "    batch_t = torch.ones(num_batch, 1, 1, device=device) * t\n",
    "    noisy_batch = flow._corrupt_batch(batch, t=batch_t)\n",
    "    noisy_batch['t']\n",
    "    with torch.no_grad():\n",
    "        model_out = flow.forward(noisy_batch)\n",
    "    all_pred_rots_vf.append(du.to_numpy(model_out['pred_rots_vf']))\n",
    "    all_pred_transrot.append((model_out['pred_trans'], model_out['pred_rots'].get_rot_mats()))\n",
    "    all_pred_ca.append(du.to_numpy(model_out['pred_trans']))\n",
    "\n",
    "    gt_trans_t = noisy_batch['trans_t']\n",
    "    gt_rotmats_t = noisy_batch['rotmats_t']\n",
    "\n",
    "    gt_rot_vf = so3_utils.calc_rot_vf(\n",
    "        noisy_batch['rotmats_t'].type(torch.float32),\n",
    "        noisy_batch['rotmats_1'].type(torch.float32)\n",
    "    )\n",
    "    all_gt_rots_vf.append(du.to_numpy(gt_rot_vf))\n",
    "\n",
    "    noisy_gt_atom37 = atom37_from_trans_rot(\n",
    "        gt_trans_t.detach().cpu(),\n",
    "        gt_rotmats_t.detach().cpu(),\n",
    "        noisy_batch['res_mask'].detach().cpu()\n",
    "    )\n",
    "    noisy_gt_atom37 = du.to_numpy(noisy_gt_atom37)\n",
    "    all_gt_atom37.append(noisy_gt_atom37)\n",
    "\n",
    "all_gt_rots_vf = np.stack(all_gt_rots_vf)\n",
    "all_pred_rots_vf = np.stack(all_pred_rots_vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples\n",
    "all_pred_ca = np.stack(all_pred_ca)\n",
    "all_pred_atom37 = np.stack(all_atom.transrot_to_atom37(\n",
    "    all_pred_transrot,\n",
    "    noisy_batch['res_mask']\n",
    "))\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_timesteps, num_batch, num_res, _, _ = all_pred_atom37.shape\n",
    "\n",
    "for i in list(np.linspace(0, num_timesteps-1, 10).astype(int)):\n",
    "    t = ts[i]\n",
    "    atom37_t = all_pred_atom37[i]\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        atom37_t,\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'model_out_len_{num_res}_t_{t:.2f}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        all_gt_atom37[i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'gt_len_{num_res}_t_{t:.2f}.pdb'),\n",
    "        no_indexing=True)\n",
    "    \n",
    "    print(f'Done with sample {i}, t={t:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rots_vf_rmsd = np.linalg.norm(all_gt_rots_vf - all_pred_rots_vf, axis=-1).reshape(num_timesteps, -1)\n",
    "rots_rmsd = np.mean(rots_vf_rmsd, axis=-1)\n",
    "res_mask = batch['res_mask']\n",
    "_, aligned_rmsd = superimpose(\n",
    "    torch.tensor(gt_ca_pos)[None].repeat(num_timesteps, 1, 1, 1) * 0.1,\n",
    "    torch.tensor(all_pred_ca).to(gt_ca_pos.device) * 0.1,\n",
    "    res_mask[None].repeat(num_timesteps, 1, 1)\n",
    ")\n",
    "aligned_trans_rmsd = du.to_numpy(torch.mean(aligned_rmsd, dim=-1))\n",
    "unaligned_trans_rmsd = np.mean(np.linalg.norm((np.stack(all_pred_ca) - du.to_numpy(gt_ca_pos)[None]) * 0.1, axis=-1), axis=(-1, -2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts, rots_rmsd, label='Rotations')\n",
    "plt.plot(ts, aligned_trans_rmsd, label='Aligned translations')\n",
    "plt.plot(ts, unaligned_trans_rmsd, label='Unaligned translations')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('RMSD')\n",
    "plt.title('Model prediction error across time t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t = 0.75\n",
    "t = torch.ones(num_batch, 1, 1, device=device) * min_t\n",
    "res_mask = batch['res_mask']\n",
    "noisy_batch = flow._corrupt_batch(batch, t=t)\n",
    "noisy_batch['t'] = t\n",
    "do_sde = False\n",
    "\n",
    "gt_trans_1 = batch['trans_1']\n",
    "gt_rotmats_1 = batch['rotmats_1']\n",
    "\n",
    "gt_atom37 = atom37_from_trans_rot(\n",
    "    gt_trans_1.detach().cpu(),\n",
    "    gt_rotmats_1.detach().cpu(),\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "gt_atom37 = du.to_numpy(gt_atom37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sampling with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom37_traj, model_traj = flow.run_sampling(\n",
    "    (noisy_batch, None),\n",
    "    return_traj=True,\n",
    "    return_model_outputs=True,\n",
    "    num_timesteps=num_timesteps,\n",
    "    do_sde=do_sde,\n",
    ")\n",
    "atom37_traj = np.stack(atom37_traj).swapaxes(0, 1)\n",
    "all_pred_atom37 = np.stack(model_traj).swapaxes(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sampling\n",
    "trans_traj = [noisy_batch['trans_t']]\n",
    "rots_traj = [noisy_batch['rotmats_t']]\n",
    "\n",
    "ts = np.linspace(min_t, 1.0, num_timesteps)\n",
    "t_1 = ts[0]\n",
    "all_pred_transrot = []\n",
    "trans_vf_traj = []\n",
    "all_gt_rots_vf = []\n",
    "all_pred_rots_vf = []\n",
    "for i,t_2 in enumerate(ts[1:]):\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Step {i+1} / {len(ts)}\")\n",
    "    d_t = t_2 - t_1\n",
    "    trans_t_1 = trans_traj[-1]\n",
    "    rots_t_1 = rots_traj[-1]\n",
    "    with torch.no_grad():\n",
    "        noisy_batch['trans_t'] = trans_t_1\n",
    "        noisy_batch['rotmats_t'] = rots_t_1\n",
    "        noisy_batch['t'] = torch.ones((num_batch, 1)).to(device) * t_1\n",
    "        model_out = flow.forward(noisy_batch)\n",
    "\n",
    "    pred_trans_1 = model_out['pred_trans']\n",
    "    # pred_trans_1 = batch['trans_1']\n",
    "    pred_rots_1 = model_out['pred_rots'].get_rot_mats()\n",
    "    # pred_rots_1 = batch['rotmats_1']\n",
    "    pred_rots_vf = model_out['pred_rots_vf']\n",
    "    all_pred_rots_vf.append(du.to_numpy(pred_rots_vf))\n",
    "    gt_rot_vf = so3_utils.calc_rot_vf(\n",
    "        noisy_batch['rotmats_t'].type(torch.float32),\n",
    "        noisy_batch['rotmats_1'].type(torch.float32)\n",
    "    )\n",
    "    all_gt_rots_vf.append(du.to_numpy(gt_rot_vf))\n",
    "    \n",
    "    all_pred_transrot.append((pred_trans_1, pred_rots_1))\n",
    "\n",
    "    trans_vf = (pred_trans_1 - trans_t_1) / (1 - t_1)\n",
    "    trans_t_2 = trans_t_1 + trans_vf * d_t\n",
    "    rots_t_2 = so3_utils.geodesic_t(\n",
    "        d_t / (1 - t_1), None, rots_t_1, rot_vf=pred_rots_vf)\n",
    "    # rots_t_2 = so3_utils.geodesic_t(\n",
    "        # d_t / (1 - t_1), pred_rots_1, rots_t_1)\n",
    "    t_1 = t_2\n",
    "    trans_traj.append(trans_t_2)\n",
    "    rots_traj.append(rots_t_2)\n",
    "\n",
    "res_mask = noisy_batch['res_mask']\n",
    "all_pred_atom37 = np.stack(all_atom.transrot_to_atom37(\n",
    "    all_pred_transrot,\n",
    "    res_mask\n",
    "))\n",
    "atom37_traj = process_trans_rot_traj(trans_traj, rots_traj, res_mask)\n",
    "final_ca_pos = atom37_traj[:, -1, :, 1]\n",
    "gt_ca_pos = noisy_batch['trans_1']\n",
    "atom37_traj = du.to_numpy(atom37_traj)\n",
    "\n",
    "gt_trans_1 = batch['trans_1']\n",
    "gt_rotmats_1 = batch['rotmats_1']\n",
    "\n",
    "gt_atom37 = atom37_from_trans_rot(\n",
    "    gt_trans_1.detach().cpu(),\n",
    "    gt_rotmats_1.detach().cpu(),\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "gt_atom37 = du.to_numpy(gt_atom37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_error_ts = torch.linalg.norm((torch.stack(trans_traj) - gt_ca_pos[None])*0.1, dim=-1)\n",
    "ca_rmsd_ts = du.to_numpy(torch.mean(ca_error_ts, dim=(-1, -2)))\n",
    "\n",
    "traj_gt_rots_vf = np.stack(all_gt_rots_vf)\n",
    "traj_pred_rots_vf = np.stack(all_pred_rots_vf)\n",
    "\n",
    "rots_error_ts = np.linalg.norm(traj_pred_rots_vf - traj_gt_rots_vf, axis=-1)\n",
    "rots_rmsd_ts = np.mean(rots_error_ts, axis=(-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.suptitle(f'Model error when sampling from t={min_t:.2f} to 1.0')\n",
    "axes[0].plot(ts, ca_rmsd_ts, label='Translations VF')\n",
    "axes[0].set_xlabel('t')\n",
    "axes[0].set_title('Translations VF')\n",
    "axes[0].set_ylabel('RMSD')\n",
    "\n",
    "axes[1].plot(ts[1:], rots_rmsd_ts, label='Rotation VF')\n",
    "axes[1].set_xlabel('t')\n",
    "axes[1].set_title('Rotation VF')\n",
    "axes[1].set_ylabel('RMSD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_batch, num_timesteps, num_res, _, _ = atom37_traj.shape\n",
    "max_save = 5\n",
    "for i, sample_traj in enumerate(atom37_traj):\n",
    "    if i >= max_save:\n",
    "        break\n",
    "    traj_path = au.write_prot_to_pdb(\n",
    "        sample_traj,\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'traj_{i}_len_{num_res}_t_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    sample_path = au.write_prot_to_pdb(\n",
    "        sample_traj[-1],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'sample_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        all_pred_atom37[-1, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'final_model_out_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        all_pred_atom37[:, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'pred_traj_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        gt_atom37[i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'gt_{i}_len_{num_res}_ts_{num_timesteps}.pdb',\n",
    "        ),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    print(f'Done with sample {i}')\n",
    "final_samples = atom37_traj[:, -1]\n",
    "_ = au.write_prot_to_pdb(\n",
    "    final_samples,\n",
    "    os.path.join(\n",
    "        save_dir,\n",
    "        'all_samples.pdb'),\n",
    "    no_indexing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_batch, num_timesteps, num_res, _, _ = atom37_traj.shape\n",
    "max_save = 5\n",
    "for i, sample_traj in enumerate(atom37_traj):\n",
    "    if i >= max_save:\n",
    "        break\n",
    "    for j in list(np.linspace(0, num_timesteps-2, 10).astype(int)):\n",
    "        t = f'{ts[j]:.2f}'.replace('.', '')\n",
    "        _ = au.write_prot_to_pdb(\n",
    "            all_pred_atom37[j, i],\n",
    "            os.path.join(\n",
    "                save_dir,\n",
    "                f'model_out_{i}_t_{t}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "            no_indexing=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
