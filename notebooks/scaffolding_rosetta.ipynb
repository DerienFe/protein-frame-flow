{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from models.flow_module import FlowModule\n",
    "import torch\n",
    "from data.pdb_dataloader import PdbDataModule\n",
    "import GPUtil\n",
    "from data import utils as du\n",
    "import numpy as np\n",
    "import tree\n",
    "from data import so3_utils\n",
    "from data import all_atom\n",
    "from analysis import utils as au\n",
    "from openfold.utils.superimposition import superimpose\n",
    "from data.interpolant import Interpolant\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'notebook_samples/'\n",
    "num_timesteps = 100\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "cuda_id = GPUtil.getAvailable(order='memory', limit = 8)[0]\n",
    "device = f'cuda:{cuda_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup lightning module\n",
    "\n",
    "ckpt_dir = '../ckpt/se3-fm/scope_256_scaffolding/2023-10-24_21-13-38/'\n",
    "# ckpt_dir = '../ckpt/se3-fm/swiss_prot_scaffolding/2023-10-25_08-43-27/'\n",
    "ckpt_path = os.path.join(ckpt_dir, 'last.ckpt')\n",
    "\n",
    "base_path = '../configs/base.yaml'\n",
    "base_cfg = OmegaConf.load(base_path)\n",
    "\n",
    "cfg_path = os.path.join(ckpt_dir, 'config.yaml')\n",
    "ckpt_cfg = OmegaConf.load(cfg_path)\n",
    "\n",
    "OmegaConf.set_struct(base_cfg, False)\n",
    "OmegaConf.set_struct(ckpt_cfg, False)\n",
    "cfg = OmegaConf.merge(base_cfg, ckpt_cfg)\n",
    "cfg.experiment.checkpointer.dirpath = './'\n",
    "cfg.experiment.rescale_time = False\n",
    "cfg.data.dataset.csv_path = '../preprocessed/metadata.csv'\n",
    "cfg.data.dataset.min_plddt_percent = None\n",
    "cfg.data.dataset.max_num_res = 256\n",
    "\n",
    "\n",
    "flow = FlowModule.load_from_checkpoint(\n",
    "    checkpoint_path=ckpt_path,\n",
    "    cfg=cfg,\n",
    "    map_location=device,\n",
    ")\n",
    "_ = flow.eval()\n",
    "\n",
    "interpolant = Interpolant(cfg.interpolant) \n",
    "interpolant.set_device(device)\n",
    "\n",
    "# Set up data module\n",
    "data_module = PdbDataModule(cfg.data)\n",
    "data_module.setup('fit')\n",
    "train_dataloader = data_module.train_dataloader(\n",
    "    num_replicas=1,\n",
    "    rank=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unconditional sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom37_traj, model_traj, _ = interpolant.sample(1, 100, flow.model)\n",
    "atom37_traj = torch.concatenate(atom37_traj, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = au.write_prot_to_pdb(\n",
    "    du.to_numpy(atom37_traj),\n",
    "    './traj.pdb',\n",
    "    no_indexing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motif scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num res 79\n"
     ]
    }
   ],
   "source": [
    "batch = next(data_iter)\n",
    "trans_1 = batch['trans_1'][:1].to(device)\n",
    "rotmats_1 = batch['rotmats_1'][:1].to(device)\n",
    "num_batch, num_res, _ = trans_1.shape\n",
    "print(f'num res {num_res}')\n",
    "\n",
    "gt_atom37 = all_atom.atom37_from_trans_rot(\n",
    "    batch['trans_1'][:1],\n",
    "    batch['rotmats_1'][:1],\n",
    "    batch['res_mask'][:1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse_mask = torch.ones(num_batch, num_res, device=device)\n",
    "diffuse_mask[:, 10:15] = 0.0\n",
    "diffuse_mask[:, 50:55] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom37_traj, model_traj, _ = interpolant.sample(\n",
    "    num_batch, num_res, flow.model,\n",
    "    trans_1=trans_1, rotmats_1=rotmats_1, diffuse_mask=diffuse_mask)\n",
    "atom37_traj = torch.concatenate(atom37_traj, dim=0)\n",
    "\n",
    "b_factor = du.to_numpy(diffuse_mask[0, :, None].repeat(1, 37) * 100).astype(int)\n",
    "# _ = au.write_prot_to_pdb(\n",
    "#     du.to_numpy(atom37_traj),\n",
    "#     './scaffold_traj.pdb',\n",
    "#     no_indexing=False,\n",
    "#     b_factors=b_factor\n",
    "# )\n",
    "\n",
    "_ = au.write_prot_to_pdb(\n",
    "    du.to_numpy(atom37_traj)[-1],\n",
    "    './scaffold.pdb',\n",
    "    no_indexing=False,\n",
    "    b_factors=b_factor\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = au.write_prot_to_pdb(\n",
    "    du.to_numpy(gt_atom37)[0],\n",
    "    './gt_scaffold.pdb',\n",
    "    no_indexing=True,\n",
    "    b_factors=b_factor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = '/data/rsg/chemistry/jyim/projects/flow-matching/motif_scaffolding/targets/6E6R_long_motif_segments.pkl'\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    motif_pkl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 7)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motif_pkl[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(motif_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse_mask = torch.ones(num_batch, num_res, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]], device='cuda:2')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffuse_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_size = 20\n",
    "chunk_min_size = 5\n",
    "max_num_motifs = motif_size // chunk_min_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sizes = np.sort(np.random.randint(low=chunk_min_size, high=motif_size, size=(max_num_motifs,)))\n",
    "chunk_sizes = chunk_sizes[np.cumsum(chunk_sizes) < motif_size]\n",
    "num_chunks = len(chunk_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_residues = np.random.randint(low=0, high=num_res, size=(num_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 9), (52, 12), (48, 12), (56, 14)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(seed_residues, chunk_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse_mask = torch.ones(num_res)\n",
    "for seed, chunk in zip(seed_residues, chunk_sizes):\n",
    "    diffuse_mask[seed:max(seed+chunk, num_res)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffuse_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found batch with 127 residues, 44 batch size\n",
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Search for a reasonable batch\n",
    "stop_search = False\n",
    "while not stop_search: \n",
    "    batch = next(data_iter)\n",
    "    num_batch, num_res, _ = batch['trans_1'].shape\n",
    "    if num_res > 120:\n",
    "        stop_search = True\n",
    "num_batch, num_res, _ = batch['trans_1'].shape\n",
    "print(f'Found batch with {num_res} residues, {num_batch} batch size')\n",
    "\n",
    "# Set up device and cuda\n",
    "# device = 'cpu'\n",
    "print(f'Using device {device}')\n",
    "flow.model = flow.model.to(device)\n",
    "batch = tree.map_structure(lambda x: x.to(device), batch)\n",
    "num_batch = batch['res_mask'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t = 1e-3\n",
    "seed = 42\n",
    "t = torch.ones(num_batch, 1, 1, device=device) * min_t\n",
    "res_mask = batch['res_mask']\n",
    "torch.manual_seed(seed)\n",
    "orig_noisy_batch = flow._corrupt_batch(batch, t=t)\n",
    "orig_noisy_batch['t'] = t\n",
    "\n",
    "do_sde = False\n",
    "gt_trans_1 = batch['trans_1'].detach().cpu()\n",
    "gt_rotmats_1 = batch['rotmats_1'].detach().cpu()\n",
    "gt_atom37 = all_atom.atom37_from_trans_rot(\n",
    "    gt_trans_1,\n",
    "    gt_rotmats_1,\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "gt_atom37 = du.to_numpy(gt_atom37)\n",
    "gt_rotvec = so3_utils.rotmat_to_rotvec(gt_rotmats_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_batch = copy.deepcopy(orig_noisy_batch)\n",
    "num_timesteps = 10\n",
    "so3_scale = 10\n",
    "ts = np.linspace(min_t, 1.0 - min_t, num_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(trans_t, rots_t, noisy_batch, t_1):\n",
    "    noisy_batch['trans_t'] = trans_t\n",
    "    noisy_batch['rotmats_t'] = rots_t\n",
    "    noisy_batch['t'] = torch.ones((num_batch, 1)).to(device) * t_1\n",
    "    with torch.no_grad():\n",
    "        model_out = flow.forward(noisy_batch)\n",
    "    return model_out\n",
    "\n",
    "def so3_vf_t(t, mats_1, mats_t):\n",
    "    return 10.0 * so3_utils.calc_rot_vf(mats_t, mats_1)\n",
    "    # return 1 / (1 - t) * so3_utils.calc_rot_vf(mats_t, mats_1)\n",
    "r3_vf_t = lambda t, trans, trans_t: (trans - trans_t) / (1 - t)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sampling with RK4\n",
    "t_1 = ts[0]\n",
    "all_pred_transrot = []\n",
    "trans_vf_traj = []\n",
    "all_pred_rots_vf = []\n",
    "all_gt_rots_vf = []\n",
    "trans_rot_traj = [(noisy_batch['trans_t'], noisy_batch['rotmats_t'])]\n",
    "r3_vf_t = lambda t, trans, trans_t: (trans - trans_t) / (1 - t)\n",
    "for i,t_2 in enumerate(ts[1:]):\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Step {i+1} / {len(ts)}\")\n",
    "    d_t = t_2 - t_1\n",
    "    trans_t_1, rots_t_1 = trans_rot_traj[-1]\n",
    "\n",
    "    k1 = run_model(trans_t_1, rots_t_1, noisy_batch, t_1)\n",
    "    trans_k1 = r3_vf_t(t_1, k1['pred_trans'], trans_t_1)\n",
    "    rots_k1 = so3_vf_t(t_1, k1['pred_rots'].get_rot_mats(), rots_t_1)\n",
    "\n",
    "    trans_input_k2 = trans_t_1 + d_t * trans_k1 / 3\n",
    "    rots_input_k2 = torch.einsum(\n",
    "        \"...ij,...jk->...ik\",\n",
    "        rots_t_1,\n",
    "        so3_utils.rotvec_to_rotmat(d_t * rots_k1 / 3)\n",
    "    )\n",
    "    t_k2 = t_1 + d_t / 3\n",
    "    \n",
    "    k2 = run_model(trans_input_k2, rots_input_k2, noisy_batch, t_k2)\n",
    "    trans_k2 = r3_vf_t(t_k2, k2['pred_trans'], trans_input_k2)\n",
    "    rots_k2 = so3_vf_t(t_k2, k2['pred_rots'].get_rot_mats(), rots_input_k2)\n",
    "\n",
    "    trans_input_k3 = trans_t_1 + d_t * (trans_k2 - trans_k1/3)\n",
    "    rots_input_k3 = torch.einsum(\n",
    "        \"...ij,...jk->...ik\",\n",
    "        rots_t_1,\n",
    "        so3_utils.rotvec_to_rotmat(d_t * rots_k2 / 3)\n",
    "    )\n",
    "    t_k3 = t_1 + d_t * 2 / 3\n",
    "    \n",
    "    k3 = run_model(trans_input_k3, rots_input_k3, noisy_batch, t_k3)\n",
    "    trans_k3 = r3_vf_t(t_k3, k3['pred_trans'], trans_input_k3)\n",
    "    rots_k3 = so3_vf_t(t_k3, k3['pred_rots'].get_rot_mats(), rots_input_k3)\n",
    "\n",
    "    trans_input_k4 = trans_t_1 + d_t * (trans_k1 - trans_k2 + trans_k3)\n",
    "    rots_input_k4 = torch.einsum(\n",
    "        \"...ij,...jk->...ik\",\n",
    "        rots_t_1,\n",
    "        so3_utils.rotvec_to_rotmat(d_t * rots_k3 / 3)\n",
    "    )\n",
    "    t_k4 = t_1 + d_t\n",
    "    \n",
    "    k4 = run_model(trans_input_k4, rots_input_k4, noisy_batch, t_k4)\n",
    "    trans_k4 = r3_vf_t(t_k4, k4['pred_trans'], trans_input_k4)\n",
    "    rots_k4 = so3_vf_t(t_k4, k4['pred_rots'].get_rot_mats(), rots_input_k4)\n",
    "    \n",
    "    # r3_vf_t = lambda t, trans, trans_t: (trans - trans_t) / (1 - t)\n",
    "    # k1 = r3_vf_t(t_1, trans_nm_1, trans_t)\n",
    "    # k2 = r3_vf_t(t_1 + d_t / 3, trans_nm_1, trans_t + d_t * k1 / 3)\n",
    "    # k3 = r3_vf_t(t_1 + d_t * 2 / 3, trans_nm_1, trans_t + d_t * (k2 - k1/3))\n",
    "    # k4 = r3_vf_t(t_1 + d_t, trans_nm_1, trans_t + d_t * (k1 - k2 + k3))\n",
    "    # trans_t_1 = trans_t + (k1 + 3 * (k2 + k3) + k4) * d_t * 0.125\n",
    "\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    #     noisy_batch['trans_t'] = trans_t_1\n",
    "    #     noisy_batch['rotmats_t'] = rots_t_1\n",
    "    #     noisy_batch['t'] = torch.ones((num_batch, 1)).to(device) * t_1\n",
    "    #     model_out = flow.forward(noisy_batch)\n",
    "\n",
    "    pred_trans_1 = k1['pred_trans']\n",
    "    pred_rots_1 = k1['pred_rots'].get_rot_mats()\n",
    "    pred_rots_vf = k1['pred_rots_vf']\n",
    "    all_pred_rots_vf.append(du.to_numpy(pred_rots_vf))\n",
    "    gt_rot_vf = so3_utils.calc_rot_vf(\n",
    "        noisy_batch['rotmats_t'].type(torch.float32),\n",
    "        noisy_batch['rotmats_1'].type(torch.float32)\n",
    "    )\n",
    "    all_gt_rots_vf.append(du.to_numpy(gt_rot_vf))\n",
    "    \n",
    "    all_pred_transrot.append((pred_trans_1, pred_rots_1))\n",
    "\n",
    "    # trans_vf = (pred_trans_1 - trans_t_1) * 2.0\n",
    "    trans_vf = (pred_trans_1 - trans_t_1) / (1 - t_1)\n",
    "    # if i == num_timesteps-2:\n",
    "    if False:\n",
    "        trans_t_2 = k1['pred_trans']\n",
    "        rots_t_2 = k1['pred_rots'].get_rot_mats()\n",
    "    else:\n",
    "        # trans_t_2 = trans_t_1 + trans_vf * d_t\n",
    "        trans_t_2 = trans_t_1 + (trans_k1 + 3 * (trans_k2 + trans_k3) + trans_k4) * d_t * 0.125\n",
    "        mat_update = so3_utils.rotvec_to_rotmat((rots_k1 + 3 * (rots_k2 + rots_k3) + rots_k4) * d_t * 0.125)\n",
    "        rots_t_2 = torch.einsum(\"...ij,...jk->...ik\", rots_t_1, mat_update)    \n",
    "        \n",
    "        # TODO: Temporary\n",
    "        # rots_out = run_model(trans_t_2, rots_t_1, noisy_batch, t_1)\n",
    "        # pred_rots_vf = rots_out['pred_rots_vf']\n",
    "        # rots_t_2 = so3_utils.geodesic_t(\n",
    "        #     so3_scale * d_t, None, rots_t_1, rot_vf=pred_rots_vf)\n",
    "\n",
    "    t_1 = t_2\n",
    "    trans_rot_traj.append((trans_t_2, rots_t_2))\n",
    "\n",
    "pred_atom37_traj = all_atom.transrot_to_atom37(\n",
    "    all_pred_transrot,\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "atom37_traj = all_atom.transrot_to_atom37(\n",
    "    trans_rot_traj,\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "pred_trans_traj = torch.stack([x[0] for x in all_pred_transrot]).detach().cpu()\n",
    "pred_rots_traj = torch.stack([x[1] for x in all_pred_transrot]).detach().cpu()\n",
    "pred_rotvec_traj = so3_utils.rotmat_to_rotvec(pred_rots_traj)\n",
    "trans_traj = torch.stack([x[0] for x in trans_rot_traj]).detach().cpu()\n",
    "rots_traj = torch.stack([x[1] for x in trans_rot_traj]).detach().cpu()\n",
    "rotvec_traj = so3_utils.rotmat_to_rotvec(rots_traj)\n",
    "output_pred_atom37_traj = du.to_numpy(torch.stack(pred_atom37_traj))\n",
    "output_atom37_traj = du.to_numpy(torch.stack(atom37_traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with sample 0\n",
      "Done with sample 1\n"
     ]
    }
   ],
   "source": [
    "# Save samples\n",
    "save_dir = f'notebook_samples/rk4/ts_{num_timesteps}/scale_so3_{so3_scale}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_timesteps, num_batch, num_res, _, _ = output_atom37_traj.shape\n",
    "\n",
    "max_save = 2\n",
    "for i in range(num_batch):\n",
    "    if i >= max_save:\n",
    "        break\n",
    "    traj_path = au.write_prot_to_pdb(\n",
    "        output_atom37_traj[:, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'traj_{i}_len_{num_res}_t_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    sample_path = au.write_prot_to_pdb(\n",
    "        output_atom37_traj[-1, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'sample_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    \n",
    "    _ = au.write_prot_to_pdb(\n",
    "        output_pred_atom37_traj[-1, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'final_model_out_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        output_pred_atom37_traj[:, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'pred_traj_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        gt_atom37[i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'gt_{i}_len_{num_res}_ts_{num_timesteps}.pdb',\n",
    "        ),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    print(f'Done with sample {i}')\n",
    "\n",
    "final_samples = output_atom37_traj[-1]\n",
    "_ = au.write_prot_to_pdb( \n",
    "    final_samples,\n",
    "    os.path.join(\n",
    "        save_dir,\n",
    "        'all_samples.pdb'),\n",
    "    no_indexing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_batch = copy.deepcopy(orig_noisy_batch)\n",
    "num_timesteps = 100\n",
    "so3_scale = 100.0\n",
    "r3_scale = 1.0\n",
    "ts = np.linspace(min_t, 1.0 - min_t, num_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rsg/chemistry/jyim/mambaforge/envs/fm/lib/python3.10/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n"
     ]
    }
   ],
   "source": [
    "# Run sampling with Euler\n",
    "t_1 = ts[0]\n",
    "all_pred_transrot = []\n",
    "trans_vf_traj = []\n",
    "all_pred_rots_vf = []\n",
    "all_gt_rots_vf = []\n",
    "trans_rot_traj = [(noisy_batch['trans_t'], noisy_batch['rotmats_t'])]\n",
    "for i,t_2 in enumerate(ts[1:]):\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Step {i+1} / {len(ts)}\")\n",
    "    d_t = t_2 - t_1\n",
    "    trans_t_1, rots_t_1 = trans_rot_traj[-1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        noisy_batch['trans_t'] = trans_t_1\n",
    "        noisy_batch['rotmats_t'] = rots_t_1\n",
    "        noisy_batch['t'] = torch.ones((num_batch, 1)).to(device) * t_1\n",
    "        model_out = flow.forward(noisy_batch)\n",
    "\n",
    "    pred_trans_1 = model_out['pred_trans']\n",
    "    pred_rots_1 = model_out['pred_rots'].get_rot_mats()\n",
    "    pred_rots_vf = model_out['pred_rots_vf']\n",
    "    all_pred_rots_vf.append(du.to_numpy(pred_rots_vf))\n",
    "    gt_rot_vf = so3_utils.calc_rot_vf(\n",
    "        noisy_batch['rotmats_t'].type(torch.float32),\n",
    "        noisy_batch['rotmats_1'].type(torch.float32)\n",
    "    )\n",
    "    all_gt_rots_vf.append(du.to_numpy(gt_rot_vf))\n",
    "    \n",
    "    all_pred_transrot.append((pred_trans_1, pred_rots_1))\n",
    "\n",
    "    # trans_vf = (pred_trans_1 - trans_t_1) * 2.0\n",
    "    # trans_vf = (pred_trans_1 - trans_t_1) / (1 - t_1)\n",
    "    if i == num_timesteps - 2:\n",
    "        trans_t_2 = model_out['pred_trans']\n",
    "        rots_t_2 = model_out['pred_rots'].get_rot_mats()\n",
    "    else:\n",
    "        trans_t_2 = trans_t_1 + r3_scale * d_t * (pred_trans_1 - trans_t_1) / (1 - t_1)\n",
    "        rots_t_2 = so3_utils.geodesic_t(\n",
    "            so3_scale * d_t, None, rots_t_1, rot_vf=pred_rots_vf)\n",
    "\n",
    "    t_1 = t_2\n",
    "    trans_rot_traj.append((trans_t_2, rots_t_2))\n",
    "\n",
    "pred_atom37_traj = all_atom.transrot_to_atom37(\n",
    "    all_pred_transrot,\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "atom37_traj = all_atom.transrot_to_atom37(\n",
    "    trans_rot_traj,\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "pred_trans_traj = torch.stack([x[0] for x in all_pred_transrot]).detach().cpu()\n",
    "pred_rots_traj = torch.stack([x[1] for x in all_pred_transrot]).detach().cpu()\n",
    "pred_rotvec_traj = so3_utils.rotmat_to_rotvec(pred_rots_traj)\n",
    "trans_traj = torch.stack([x[0] for x in trans_rot_traj]).detach().cpu()\n",
    "rots_traj = torch.stack([x[1] for x in trans_rot_traj]).detach().cpu()\n",
    "rotvec_traj = so3_utils.rotmat_to_rotvec(rots_traj)\n",
    "output_pred_atom37_traj = du.to_numpy(torch.stack(pred_atom37_traj))\n",
    "output_atom37_traj = du.to_numpy(torch.stack(atom37_traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with sample 0\n",
      "Done with sample 1\n"
     ]
    }
   ],
   "source": [
    "# Save samples\n",
    "save_dir = f'notebook_samples/euler/scale_so3_{so3_scale}/scale_r3_{r3_scale}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_timesteps, num_batch, num_res, _, _ = output_atom37_traj.shape\n",
    "\n",
    "max_save = 2\n",
    "for i in range(num_batch):\n",
    "    if i >= max_save:\n",
    "        break\n",
    "    traj_path = au.write_prot_to_pdb(\n",
    "        output_atom37_traj[:, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'traj_{i}_len_{num_res}_t_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    sample_path = au.write_prot_to_pdb(\n",
    "        output_atom37_traj[-1, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'sample_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    \n",
    "    _ = au.write_prot_to_pdb(\n",
    "        output_pred_atom37_traj[-1, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'final_model_out_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        output_pred_atom37_traj[:, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'pred_traj_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        gt_atom37[i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'gt_{i}_len_{num_res}_ts_{num_timesteps}.pdb',\n",
    "        ),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    print(f'Done with sample {i}')\n",
    "\n",
    "final_samples = output_atom37_traj[-1]\n",
    "_ = au.write_prot_to_pdb( \n",
    "    final_samples,\n",
    "    os.path.join(\n",
    "        save_dir,\n",
    "        'all_samples.pdb'),\n",
    "    no_indexing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
