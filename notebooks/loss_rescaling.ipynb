{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from models.flow_module import FlowModule\n",
    "import torch\n",
    "from data.pdb_dataloader import PdbDataModule\n",
    "import glob\n",
    "import GPUtil\n",
    "from data import utils as du\n",
    "import numpy as np\n",
    "import tree\n",
    "from data import so3_utils\n",
    "from data import all_atom\n",
    "from analysis import utils as au\n",
    "from openfold.utils.superimposition import superimpose\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotnine as gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'notebook_debug/'\n",
    "num_timesteps = 100\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../configs/base.yaml'\n",
    "\n",
    "cfg = OmegaConf.load(base_path)\n",
    "cfg.experiment.checkpointer.dirpath = './'\n",
    "cfg.data.dataset.csv_path = '../preprocessed/metadata.csv'\n",
    "\n",
    "flow = FlowModule(\n",
    "    model_cfg=cfg.model,\n",
    "    experiment_cfg=cfg.experiment\n",
    ")\n",
    "\n",
    "_ = flow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data module\n",
    "data_module = PdbDataModule(cfg.data)\n",
    "data_module.setup('fit')\n",
    "train_dataloader = data_module.train_dataloader(\n",
    "    num_replicas=1,\n",
    "    rank=1\n",
    ")\n",
    "data_iter = iter(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a reasonable batch\n",
    "stop_search = False\n",
    "while not stop_search: \n",
    "    batch = next(data_iter)\n",
    "    num_batch, num_res, _ = batch['trans_1'].shape\n",
    "    if num_res > 100:\n",
    "        stop_search = True\n",
    "print(f'Found batch with {num_res} residues, {num_batch} batch size')\n",
    "\n",
    "# Set up device and cuda\n",
    "num_batch, num_res, _ = batch['trans_1'].shape\n",
    "cuda_id = GPUtil.getAvailable(order='memory', limit = 8)[0]\n",
    "device = 'cpu'\n",
    "print(f'Using device {device}')\n",
    "flow.model = flow.model.to(device)\n",
    "batch = tree.map_structure(lambda x: x.to(device), batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take lots of samples\n",
    "num_samples = 100\n",
    "all_noisy_batches = [flow._corrupt_batch(batch) for _ in range(num_samples)]\n",
    "\n",
    "all_t = du.to_numpy(torch.stack([x['t'] for x in all_noisy_batches]).reshape(-1))\n",
    "t_factor = 1/(1 - all_t[..., None, None])\n",
    "\n",
    "all_rotmats_t = torch.stack([x['rotmats_t'] for x in all_noisy_batches]).reshape(-1, num_res, 3, 3)\n",
    "all_rotmats_1 = torch.stack([x['rotmats_1'] for x in all_noisy_batches]).reshape(-1, num_res, 3, 3)\n",
    "gt_rot_vf = so3_utils.calc_rot_vf(\n",
    "    all_rotmats_t.type(torch.float32),\n",
    "    all_rotmats_1.type(torch.float32)\n",
    ") * t_factor\n",
    "\n",
    "all_trans_t = torch.stack([x['trans_t'] for x in all_noisy_batches]).reshape(-1, num_res, 3)\n",
    "all_trans_1 = torch.stack([x['trans_1'] for x in all_noisy_batches]).reshape(-1, num_res, 3)\n",
    "gt_trans_vf = (all_trans_1 - all_trans_t) * 0.1 * t_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_vf_magnitudes = np.mean(np.linalg.norm(du.to_numpy(gt_rot_vf), axis=-1), axis=-1)\n",
    "trans_vf_magnitudes = np.mean(np.linalg.norm(du.to_numpy(gt_trans_vf), axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(all_t, rot_vf_magnitudes, label='Rotation')\n",
    "plt.scatter(all_t, trans_vf_magnitudes, label='Translations')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(r'$||x||_2^2$')\n",
    "plt.title('Normalized loss magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_vf_magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noisy_batches = []\n",
    "for _ in range(10):\n",
    "    all_noisy_batches.append(flow._corrupt_batch(batch))\n",
    "all_noisy_batches_2 = [flow._corrupt_batch(batch) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ts = [x['t'] for x in all_noisy_batches]\n",
    "all_ts_2 = [x['t'] for x in all_noisy_batches_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ts[3][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ts_2[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sample = torch.stack([x['t'] for x in all_noisy_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsd_df = pd.DataFrame({\n",
    "    't': all_t,\n",
    "    'Rotation VF': rot_vf_magnitudes,\n",
    "    'Translation VF': trans_vf_magnitudes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = gg.ggplot(gg.aes(x='t', y='Rotation VF'), rmsd_df)\n",
    "p + gg.geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vf_magnitudes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(all_t[:1000], rot_vf_magnitudes[:1000])\n",
    "plt.scatter(all_t[:1000], trans_vf_magnitudes[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take lots of samples\n",
    "num_samples = 1000\n",
    "all_noisy_batches = [flow._corrupt_batch(batch) for _ in range(num_samples)]\n",
    "\n",
    "all_t = du.to_numpy(torch.stack([x['t'] for x in all_noisy_batches]).reshape(-1))\n",
    "all_rotmats_t = torch.stack([x['rotmats_t'] for x in all_noisy_batches]).reshape(-1, num_res, 3, 3)\n",
    "all_trans_t = torch.stack([x['trans_t'] for x in all_noisy_batches]).reshape(-1, num_res, 3)\n",
    "all_rotvecs_t = so3_utils.rotmat_to_rotvec(all_rotmats_t)\n",
    "all_gt_rotvec = gt_rotvec[None].repeat(num_samples, 1, 1, 1).reshape(-1, num_res, 3)\n",
    "all_gt_trans = gt_trans_1[None].repeat(num_samples, 1, 1, 1).reshape(-1, num_res, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_rot_vf = so3_utils.calc_rot_vf(\n",
    "    noisy_batch['rotmats_t'].type(torch.float32),\n",
    "    gt_rotmats_1.type(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_dist_t = du.to_numpy(torch.mean(torch.linalg.norm(all_rotvecs_t - all_gt_rotvec, dim=-1), dim=-1))\n",
    "trans_dist_t = du.to_numpy(torch.mean(torch.linalg.norm(all_trans_t - all_gt_trans, dim=-1), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_t, trans_dist_t)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('RMSD')\n",
    "plt.title(r'RMSD of $x_t$ and $x_1$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_t, rot_dist_t)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('RMSD')\n",
    "plt.title(r'RMSD of $r_t$ and $r_1$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gt_rot_vf = []\n",
    "for noisy_batch in all_noisy_batches:\n",
    "    gt_rot_vf = so3_utils.calc_rot_vf(\n",
    "        noisy_batch['rotmats_t'].type(torch.float32),\n",
    "        gt_rotmats_1.type(torch.float32)\n",
    "    )\n",
    "    all_gt_rot_vf.append(gt_rot_vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rot_vf_mag = du.to_numpy(torch.concat([torch.linalg.norm(x, dim=-1) for x in all_gt_rot_vf]).reshape(-1, num_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_t, np.mean(all_rot_vf_mag, axis=-1))\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('RMSD')\n",
    "plt.title('Magnitude of rotation vector field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rot_vf_mag.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction at different timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ca_pos = batch['trans_1']\n",
    "device = gt_ca_pos.device\n",
    "num_batch = gt_ca_pos.shape[0]\n",
    "ts = np.linspace(1e-3, 1.0, num_timesteps)\n",
    "all_pred_ca = []\n",
    "all_pred_transrot = []\n",
    "all_gt_atom37 = []\n",
    "for i,t in enumerate(ts):\n",
    "    if i % 100 == 0:\n",
    "        print(f'On t={t:.2f}')\n",
    "    batch_t = torch.ones(num_batch, 1, 1, device=device) * t\n",
    "    noisy_batch = flow._corrupt_batch(batch, t=batch_t)\n",
    "    noisy_batch['t']\n",
    "    with torch.no_grad():\n",
    "        model_out = flow.forward(noisy_batch)\n",
    "    all_pred_transrot.append((model_out['pred_trans'], model_out['pred_rotmats']))\n",
    "    all_pred_ca.append(du.to_numpy(model_out['pred_trans']))\n",
    "\n",
    "    gt_trans_t = noisy_batch['trans_t']\n",
    "    gt_rotmats_t = noisy_batch['rotmats_t']\n",
    "\n",
    "    noisy_gt_atom37 = atom37_from_trans_rot(\n",
    "        gt_trans_t.detach().cpu(),\n",
    "        gt_rotmats_t.detach().cpu(),\n",
    "        noisy_batch['res_mask'].detach().cpu()\n",
    "    )\n",
    "    noisy_gt_atom37 = du.to_numpy(noisy_gt_atom37)\n",
    "    all_gt_atom37.append(noisy_gt_atom37)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples\n",
    "\n",
    "all_pred_ca = np.stack(all_pred_ca)\n",
    "all_pred_atom37 = np.stack(all_atom.transrot_to_atom37(\n",
    "    all_pred_transrot,\n",
    "    noisy_batch['res_mask']\n",
    "))\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_timesteps, num_batch, num_res, _, _ = all_pred_atom37.shape\n",
    "\n",
    "for i in list(np.linspace(0, num_timesteps-1, 10).astype(int)):\n",
    "    t = ts[i]\n",
    "    atom37_t = all_pred_atom37[i]\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        atom37_t,\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'model_out_len_{num_res}_t_{t:.2f}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        all_gt_atom37[i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'gt_len_{num_res}_t_{t:.2f}.pdb'),\n",
    "        no_indexing=True)\n",
    "    \n",
    "    print(f'Done with sample {i}, t={t:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mask = batch['res_mask']\n",
    "aligned_sample_ca, aligned_rmsd = superimpose(\n",
    "    torch.tensor(gt_ca_pos)[None].repeat(num_timesteps, 1, 1, 1),\n",
    "    torch.tensor(all_pred_ca).to(gt_ca_pos.device),\n",
    "    res_mask[None].repeat(num_timesteps, 1, 1)\n",
    ")\n",
    "# torch.mean(aligned_rmsd)\n",
    "ts_rmsd = du.to_numpy(torch.mean(aligned_rmsd, dim=-1))\n",
    "\n",
    "plt.plot(ts, ts_rmsd)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('RMSD to ground truth')\n",
    "# plt.plot(ts, noisy_rmsds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_rmsd = du.to_numpy(aligned_rmsd)\n",
    "for i in range(np_rmsd.shape[1]):\n",
    "    plt.plot(ts, np_rmsd[:, i])\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('RMSD')\n",
    "plt.suptitle('RMSD between model\\'s x_0 output and ground truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t = 1e-3\n",
    "t = torch.ones(num_batch, 1, 1, device=device) * min_t\n",
    "res_mask = batch['res_mask']\n",
    "noisy_batch = flow._corrupt_batch(batch, t=t)\n",
    "noisy_batch['t'] = t\n",
    "do_sde = False\n",
    "debug_trans = False\n",
    "debug_rots = True\n",
    "\n",
    "gt_trans_1 = batch['trans_1']\n",
    "gt_rotmats_1 = batch['rotmats_1']\n",
    "\n",
    "gt_atom37 = atom37_from_trans_rot(\n",
    "    gt_trans_1.detach().cpu(),\n",
    "    gt_rotmats_1.detach().cpu(),\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "gt_atom37 = du.to_numpy(gt_atom37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom37_traj, model_traj = flow.run_sampling(\n",
    "    (noisy_batch, None),\n",
    "    return_traj=True,\n",
    "    return_model_outputs=True,\n",
    "    num_timesteps=num_timesteps,\n",
    "    do_sde=do_sde,\n",
    "    debug_trans=debug_trans,\n",
    "    debug_rots=debug_rots,\n",
    ")\n",
    "atom37_traj = np.stack(atom37_traj).swapaxes(0, 1)\n",
    "model_traj = np.stack(model_traj).swapaxes(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_batch, num_timesteps, num_res, _, _ = atom37_traj.shape\n",
    "max_save = 5\n",
    "de_form = 'sde' if do_sde else 'ode'\n",
    "for i, sample_traj in enumerate(atom37_traj):\n",
    "    if i >= max_save:\n",
    "        break\n",
    "    traj_path = au.write_prot_to_pdb(\n",
    "        sample_traj,\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'traj_{i}_len_{num_res}_ts_{num_timesteps}_{de_form}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    sample_path = au.write_prot_to_pdb(\n",
    "        sample_traj[-1],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'sample_{i}_len_{num_res}_ts_{num_timesteps}_{de_form}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        model_traj[-1, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'final_model_out_{i}_len_{num_res}_ts_{num_timesteps}_{de_form}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        model_traj[:, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'pred_traj_{i}_len_{num_res}_ts_{num_timesteps}_{de_form}.pdb'),\n",
    "        no_indexing=True\n",
    "    )  \n",
    "    _ = au.write_prot_to_pdb(\n",
    "        gt_atom37[i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'gt_{i}_len_{num_res}_ts_{num_timesteps}.pdb',\n",
    "        ),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    print(f'Done with sample {i}')\n",
    "final_samples = atom37_traj[:, -1]\n",
    "_ = au.write_prot_to_pdb(\n",
    "    final_samples,\n",
    "    os.path.join(\n",
    "        save_dir,\n",
    "        'all_samples.pdb'),\n",
    "    no_indexing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sampling\n",
    "trans_traj = [noisy_batch['trans_t']]\n",
    "rots_traj = [noisy_batch['rotmats_t']]\n",
    "ts = np.linspace(min_t, 1.0, num_timesteps)\n",
    "t_1 = ts[0]\n",
    "all_pred_transrot = []\n",
    "trans_vf_traj = []\n",
    "for i,t_2 in enumerate(ts[1:]):\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Step {i+1} / {len(ts)}\")\n",
    "    d_t = t_2 - t_1\n",
    "    trans_t_1 = trans_traj[-1]\n",
    "    rots_t_1 = rots_traj[-1]\n",
    "    with torch.no_grad():\n",
    "        noisy_batch['trans_t'] = trans_t_1\n",
    "        noisy_batch['rotmats_t'] = rots_t_1\n",
    "        noisy_batch['t'] = torch.ones((num_batch, 1)).to(device) * t_1\n",
    "        model_out = flow.forward(noisy_batch)\n",
    "\n",
    "    pred_trans_1 = model_out['pred_trans']\n",
    "    # pred_trans_1 = batch['trans_1']\n",
    "    pred_rots_1 = model_out['pred_rotmats']\n",
    "    # pred_rots_1 = batch['rotmats_1']\n",
    "    pred_rots_vf = model_out['pred_rots_vf']\n",
    "    all_pred_transrot.append((pred_trans_1, pred_rots_1))\n",
    "\n",
    "    trans_vf = (pred_trans_1 - trans_t_1) / (1 - t_1)\n",
    "    trans_t_2 = trans_t_1 + trans_vf * d_t\n",
    "    rots_t_2 = so3_utils.geodesic_t(\n",
    "        d_t / (1 - t_1), pred_rots_1, rots_t_1, rot_vf=pred_rots_vf)\n",
    "    t_1 = t_2\n",
    "    trans_traj.append(trans_t_2)\n",
    "    rots_traj.append(rots_t_2)\n",
    "\n",
    "res_mask = noisy_batch['res_mask']\n",
    "all_pred_atom37 = np.stack(all_atom.transrot_to_atom37(\n",
    "    all_pred_transrot,\n",
    "    res_mask\n",
    "))\n",
    "atom37_traj = process_trans_rot_traj(trans_traj, rots_traj, res_mask)\n",
    "final_ca_pos = atom37_traj[:, -1, :, 1]\n",
    "gt_ca_pos = noisy_batch['trans_1']\n",
    "atom37_traj = du.to_numpy(atom37_traj)\n",
    "\n",
    "gt_trans_1 = batch['trans_1']\n",
    "gt_rotmats_1 = batch['rotmats_1']\n",
    "\n",
    "gt_atom37 = atom37_from_trans_rot(\n",
    "    gt_trans_1.detach().cpu(),\n",
    "    gt_rotmats_1.detach().cpu(),\n",
    "    res_mask.detach().cpu()\n",
    ")\n",
    "gt_atom37 = du.to_numpy(gt_atom37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_batch, num_timesteps, num_res, _, _ = atom37_traj.shape\n",
    "max_save = 5\n",
    "for i, sample_traj in enumerate(atom37_traj):\n",
    "    if i >= max_save:\n",
    "        break\n",
    "    traj_path = au.write_prot_to_pdb(\n",
    "        sample_traj,\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'traj_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    sample_path = au.write_prot_to_pdb(\n",
    "        sample_traj[-1],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'sample_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        all_pred_atom37[-1, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'final_model_out_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    _ = au.write_prot_to_pdb(\n",
    "        all_pred_atom37[:, i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'pred_traj_{i}_len_{num_res}_ts_{num_timesteps}.pdb'),\n",
    "        no_indexing=True\n",
    "    )  \n",
    "    _ = au.write_prot_to_pdb(\n",
    "        gt_atom37[i],\n",
    "        os.path.join(\n",
    "            save_dir,\n",
    "            f'gt_{i}_len_{num_res}_ts_{num_timesteps}.pdb',\n",
    "        ),\n",
    "        no_indexing=True\n",
    "    )\n",
    "    print(f'Done with sample {i}')\n",
    "final_samples = atom37_traj[:, -1]\n",
    "_ = au.write_prot_to_pdb(\n",
    "    final_samples,\n",
    "    os.path.join(\n",
    "        save_dir,\n",
    "        'all_samples.pdb'),\n",
    "    no_indexing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
