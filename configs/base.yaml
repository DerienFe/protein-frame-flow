data:
  # CSV for path and metadata to training examples.
  dataset:
    max_num_res: 128
    min_num_res: 0
    subset: null
    samples_per_eval_length: 5
    num_eval_lengths: 8
    min_eval_length: 500
    csv_path: ./preprocessed/metadata.csv
  loader:
    num_workers: 4
    prefetch_factor: 10
  sampler:
    max_batch_size: 100
    max_num_res_squared: 500_000
    use_batch_repeats: False
    num_batches: null

model:
  flow:
    use_rot_updates: True
    predict_rot_vf: False
    node_embed_size: 256
    edge_embed_size: 128
    symmetric: False
    node_features:
      c_s: ${model.flow.node_embed_size}
      c_pos_emb: 128
      c_timestep_emb: 128
      embed_t: True
      max_num_res: 2000
      timestep_int: 1000
    edge_features:
      single_bias_transition_n: 2
      c_s: ${model.flow.node_embed_size}
      c_p: ${model.flow.edge_embed_size}
      relpos_k: 64
      use_rbf: True
      num_rbf: 32
      feat_dim: 64
      num_bins: 22
      self_condition: True
    ipa:
      c_s: ${model.flow.node_embed_size}
      c_z: ${model.flow.edge_embed_size}
      c_hidden: 128
      no_heads: 8
      no_qk_points: 8
      no_v_points: 12
      seq_tfmr_num_heads: 4
      seq_tfmr_num_layers: 2
      num_blocks: 6

experiment:
  debug: False
  seed: 123
  num_devices: 2
  warm_start: null
  warm_start_cfg_override: True
  noise_trans: True
  noise_rots: True
  rescale_time: False
  use_swa: False
  min_t: 1e-3
  so3_prior: uniform
  so3_schedule: exp
  self_condition: ${model.flow.edge_features.self_condition}
  batch_ot:
    enabled: True
    cost: kabsch
    noise_per_sample: 1
    permute: False
  training:
    self_correcting: False
    loss: se3_vf_loss
    bb_atom_scale: 0.1
    translation_loss_t_upper: 1.0
    bb_atom_loss_t_lower: 0.0
    trans_scale: 0.1
    superimpose: null
    translation_loss_weight: 2.0
    t_normalize_clip: 0.9
    rotation_loss_weights: 1.0
    rotation_loss_t_upper: 1.0
    aux_loss_weight: 1.0
    aux_loss_t_pass: 0.25
  wandb:
    name: baseline
    project: se3-fm
    save_code: True
    tags: ['baseline']
  optimizer:
    lr: 0.0001
  trainer:
    overfit_batches: 0
    min_epochs: 1 # prevents early stopping
    max_epochs: 1000
    accelerator: gpu
    log_every_n_steps: 1
    deterministic: False
    strategy: ddp
    check_val_every_n_epoch: 2
    accumulate_grad_batches: 2
    num_sanity_val_steps: -1
  sampling:
    num_timesteps: 100
    prior_scale: 1.0
    do_sde: False
    vf_scaling: reverse_time
  checkpointer:
    dirpath: ckpt/${experiment.wandb.project}/${experiment.wandb.name}/${now:%Y-%m-%d}_${now:%H-%M-%S}
    save_last: True
    save_top_k: 3
    monitor: valid/non_coil_percent
    mode: max
